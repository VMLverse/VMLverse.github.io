{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfgASM7CpZoA"
      },
      "source": [
        "# MNIST Handwritten Digit Recognition in PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7RqGnqkeVWp"
      },
      "source": [
        "## Introduction\n",
        "I was reading through [FastAI's material](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) which covered the basics of a neural network while showing an example of MNIST character recognition. However it was a simple binary classifier which recognizes if a digit was 3 or 7. The complete classification was left as an open assignment. I tried looking up existing articles on MNIST character recognition and most of the articles dived right into Pytorch which was confusing for me.\n",
        "\n",
        "So in this article,  I attempt to dissect the neural network character recognition process, trying to cover the basics, implementing it manually first and then later in Pytorch. It did take me some time to complete this article, but I do find myself looking back to this article to cover the basics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsVljdzNqxgd"
      },
      "source": [
        "## Environment Setup\n",
        "Since we eventually want to code in Pytorch, I will start straight away by using torch instead of numpy so we can switch between manual methods and later replace them with standard Pytorch functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CHHGqbc2umCD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CssYZaVrapKi",
        "outputId": "32ee567d-51eb-4e73-f24c-f6fac6f3c758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WDezuMSrKpo"
      },
      "source": [
        "## Dataset Preparation\n",
        "MNIST consists of 70,000 handwritten digit images, with 60,000 allocated for training and 10,000 for testing. These images are grayscale, sized at 28x28 pixels, and centered to streamline preprocessing and expedite the setup.\n",
        "\n",
        "The dataset preparation can be described by the following steps:\n",
        "1. Download & Inspect the data\n",
        "2. Normalize the data\n",
        "3. Shuffle & Split into Mini Batches\n",
        "\n",
        "NOTE: In production systems, most of these steps would be combined together for faster and efficient computation. However, for this article, I have delved into the details for better understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SflMj9lx0aW-"
      },
      "source": [
        "### Download and Inspect the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_TqtNX5tDtu",
        "outputId": "6167d177-ec88-41e0-8008-e4de298f9200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 127058919.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz to /files/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 99210232.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 37639757.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz to /files/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7001296.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
            "\n",
            "Length of Train Dataset: 60000\n",
            "Length of each entry of the dataset: 2\n"
          ]
        }
      ],
      "source": [
        "# Create a DataLoader for the training dataset.\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    '/files/',                # Specify the directory to store the dataset.\n",
        "    train=True,               # Use the training split.\n",
        "    download=True,            # Download the dataset if not already present.\n",
        "    transform=None       # Apply the defined transformations.\n",
        ")\n",
        "print('Length of Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Length of each entry of the dataset: {}'.format(len(train_dataset[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm3tAN1V1c4B"
      },
      "source": [
        "Pytorch already has builtin MNIST dataset which can be accessed through `torchvision.datasets.MNIST`. We have downloaded 60000 train data and each train data entry has two entries: one PIL Image and one int label.\n",
        "\n",
        "Lets try accessing the dataset at index 0 and inspect it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp2_WxPj0JhK",
        "outputId": "ba6ebc82-9074-4517-ec53-ce35e3304ebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image type: <class 'PIL.Image.Image'>\n",
            "label type: <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "# Access image at index 0 and its label\n",
        "image, label = train_dataset[0]\n",
        "print('image type: {}'.format(type(image)))\n",
        "print('label type: {}'.format(type(label)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQwy3G621-E9"
      },
      "source": [
        "PIL (Python Imaging Library), often referred to as Pillow, is the most commonly used Python package for opening, editing, and displaying images. When working within Jupyter notebooks, PIL images can be automatically displayed, simplifying the image viewing process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "gQmf6vcKzzPX",
        "outputId": "b87648a9-fce7-405c-f873-6cc3694d37d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('label: {}'.format(label))\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F337BsOF2uY4"
      },
      "source": [
        "To inspect the numerical representation of this image, we can convert it into a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8ikKRAW2z8J",
        "outputId": "aa3bb7f3-791c-480c-c473-a45b002d25cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,  30,  36,  94, 154],\n",
              "       [  0,  49, 238, 253, 253, 253],\n",
              "       [  0,  18, 219, 253, 253, 253],\n",
              "       [  0,   0,  80, 156, 107, 253],\n",
              "       [  0,   0,   0,  14,   1, 154],\n",
              "       [  0,   0,   0,   0,   0, 139]], dtype=uint8)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert PIL image to NumPy array\n",
        "numpy_array = np.array(image)\n",
        "numpy_array[6:12,6:12]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irhgviH23YEV"
      },
      "source": [
        "The notation \"6:12\" specifies that we've selected rows starting from index 6 (inclusive) up to index 12 (exclusive), and the same applies to columns. In NumPy, indexing proceeds from top to bottom and left to right, so this section corresponds to the top-left corner of the image. Here's the equivalent operation using a PyTorch tensor:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cKabR4b33fD"
      },
      "source": [
        "### Normalize the data\n",
        "Normalization is an important preprocessing step that contributes to the stability, efficiency, and effectiveness of machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4KWv6JHYmGq"
      },
      "source": [
        "#### Why need normalization?\n",
        "- With image data like MNIST, converting pixel values (typically in the range [0, 255]) to a standard range (often mean zero and standard deviation one) is referred to as \"Normalization\".\n",
        "- Normalization ensures that the data is centered around zero and has a similar scale, reducing the likelihood of [vanishing or exploding gradients](https://datascience.stackexchange.com/questions/95160/how-batch-normalization-layer-resolve-the-vanishing-gradient-problem) during training.\n",
        "- By scaling the data to a standard range, the model becomes less sensitive to variations in input magnitude.\n",
        "- This helps ensure that images with different lighting conditions or contrast levels are treated consistently during training, making it easier for the model to learn the relevant patterns in the data.\n",
        "- Without data normalization, the loss values during training may be higher, and the convergence may be slower compared to a model trained with normalized data. This is because the input data's pixel values range from 0 to 255, which can lead to large gradients and slow convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzZB_KV-Yno-"
      },
      "source": [
        "\n",
        "#### How do we apply Normalization?\n",
        "Usually our first option is `StandardScaler` which is very commonly used. It works via standardizing the data (i.e. centering them), that's to bring them to a STD=1 and Mean=0. It gets affected by outliers, and should only be used if your data have Gaussian-Like Distribution.\n",
        "\n",
        "$$ StandardScaler = \\frac{x_i - mean(x)}{stddev(x)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMAPhuON6zSW"
      },
      "source": [
        "As we can see from the above formula, the first step in normalizing the data is calculating the mean and standard deviation of the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sr6mygte7ArV"
      },
      "outputs": [],
      "source": [
        "## define transformation to convert PIL to Pytorch Tensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Initialize an empty list to store the labels\n",
        "train_labels = []\n",
        "image_tensors = []\n",
        "for image, label in train_dataset:\n",
        "  image_tensors.append(transform(image).view(-1)) #loop through dataset and convert images to tensors.\n",
        "  train_labels.append(label) # extract the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUcYlP4qGP4R"
      },
      "source": [
        "**NOTE:** `transforms.ToTensor()` is used to turn the input data in the range of [0,255] to a 3-dimensional Tensor. This function automatically scales the input data to the range of [0,1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aWN1IZDpxo7"
      },
      "source": [
        "We will also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor).  This is for easier calculation when we do neural network. We can achieve this using the view method, a PyTorch function that alters a tensor's shape while preserving its contents. The -1 parameter, when applied with view, serves as a unique instruction, essentially stating, \"adjust this dimension to accommodate all available data.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppzuIwpM71xx",
        "outputId": "8f8e99d5-4b6c-4d76-cafd-4dd3b039167d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train Dataset (Tensors): 60000\n",
            "Shape of Train Dataset (Tensors): torch.Size([784])\n",
            "Type of Train Dataset (Tensors): <class 'torch.Tensor'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Length of Train Dataset (Tensors): {}'.format(len(image_tensors)))\n",
        "print('Shape of Train Dataset (Tensors): {}'.format(image_tensors[1].shape))\n",
        "print('Type of Train Dataset (Tensors): {}'.format(type(image_tensors[1])))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzIbjkxGH7Ki"
      },
      "source": [
        "In this step we can calculate the mean and median of the tensors.\n",
        "\n",
        "We use `torch.stack` to stack the list of tensors into a single tensor. dim=0 specifies that we want to stack along the batch dimension (assuming the tensors represent images). Note that although image_tensors and stacked_tensors have the same shape, we are stacking it to tensors so that we convert the array image_tensors to a tensor stacked_tensors. We do this so we can apply tensor.mean() which is not possible on an array.\n",
        "\n",
        "We then calculate the mean and standard deviation using .mean() and .std() functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwlzkz1HwLH",
        "outputId": "26704c98-66ac-4535-a4de-f11874cdcc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stacked_tensors shape: torch.Size([60000, 784])\n",
            "Mean of stacked_tensors: tensor(0.1307)\n",
            "Standard Deviation of stacked_tensors: tensor(0.3081)\n"
          ]
        }
      ],
      "source": [
        "# Stack the list of tensors into a single tensor\n",
        "stacked_tensors = torch.stack(image_tensors, dim=0)\n",
        "print('stacked_tensors shape: {}'.format(stacked_tensors.shape))\n",
        "\n",
        "\n",
        "# Calculate the mean and standard deviation\n",
        "mean = stacked_tensors.mean()\n",
        "std = stacked_tensors.std()\n",
        "\n",
        "# Print the calculated mean and standard deviation\n",
        "print(\"Mean of stacked_tensors:\", mean)\n",
        "print(\"Standard Deviation of stacked_tensors:\", std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNpb2XA0J33S"
      },
      "source": [
        "Notice the numbers 0.1307 and 0.3081? Many MNIST articles across the internet have straight away used these numbers as a method of normalizing MNIST data. Now you know that, these numbers are the mean and median of the standard MNIST train dataset.\n",
        "\n",
        "Finally, we can standardize the stacked_tensor using standard scalar method as we show above. `view` is a PyTorch method that changes the shape of a tensor without changing its contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk7rh7lBJ4QG",
        "outputId": "e8f990e4-0118-415f-c201-5ed1fe8cc789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stacked_tensors shape: torch.Size([60000, 784])\n",
            "mean shape: torch.Size([])\n",
            "mean.view(1, 1): tensor([[0.1307]])\n",
            "\n",
            "Mean of standardized_tensors: tensor(-1.5882e-09)\n",
            "Standard Deviation of standardized_tensors: tensor(1.0000)\n"
          ]
        }
      ],
      "source": [
        "# Standardize the stacked_tensors\n",
        "print('stacked_tensors shape: {}'.format(stacked_tensors.shape))\n",
        "print('mean shape: {}'.format(mean.shape))\n",
        "print('mean.view(1, 1): {}'.format(mean.view(1, 1)))\n",
        "standardized_tensors = (stacked_tensors - mean.view(1, 1)) / std.view(1, 1)\n",
        "\n",
        "# Calculate the mean and standard deviation\n",
        "standardized_mean = standardized_tensors.mean()\n",
        "standardized_std = standardized_tensors.std()\n",
        "\n",
        "# Print the calculated mean and standard deviation\n",
        "print()\n",
        "print(\"Mean of standardized_tensors:\", standardized_mean)\n",
        "print(\"Standard Deviation of standardized_tensors:\", standardized_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uNLNLPBKm0G"
      },
      "source": [
        "As we can see, we have now normalized the image tensors to a mean of ~0 and a standard deviation of 1 using the standard scalar normalization method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iFTlDHgN6RH"
      },
      "source": [
        "### Split into Mini-Batches\n",
        "\n",
        "To effectively perform optimization in deep learning, we need to calculate the loss over a subset of data items, rather than the entire dataset or a single item. Let's discuss this compromise:\n",
        "\n",
        "1. **Calculating for the Whole Dataset:** Calculating the loss for the entire dataset is accurate but time-consuming. It's often impractical, especially for large datasets, as it can be very slow.\n",
        "\n",
        "2. **Calculating for a Single Item:** Calculating the loss for just one data item is quick but highly imprecise. It doesn't provide a good estimate of how the model performs on the entire dataset, making the gradient updates unstable.\n",
        "\n",
        "3. **Using Mini-Batches:** To strike a balance, we calculate the average loss for a small group of data items known as a mini-batch. The number of data items in a mini-batch is called the batch size. A larger batch size provides a more stable estimate of gradients but can slow down training. The choice of batch size is crucial and depends on factors like the available hardware and dataset size.\n",
        "\n",
        "Using mini-batches has several advantages:\n",
        "\n",
        "- **Efficiency:** It leverages parallelism in accelerators like GPUs, which perform well when given substantial workloads. Mini-batches provide this workload efficiently.\n",
        "\n",
        "- **Stability:** It helps stabilize the training process by smoothing out noisy gradients from individual data items.\n",
        "\n",
        "- **Memory Management:** Mini-batches allow you to make the most of GPU memory without overloading it.\n",
        "\n",
        "Choosing an appropriate batch size is a practical decision in deep learning, balancing training speed and accuracy. It's an important consideration in training neural networks effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2HQIj1gOjq6"
      },
      "source": [
        "#### Shuffling\n",
        "To enhance generalization in training, introducing variation is essential. An effective way to achieve this is by diversifying the data items within each mini-batch. Instead of processing the dataset in a fixed order during each epoch, it's common practice to shuffle the dataset before creating mini-batches. This randomization promotes better learning and adaptability in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Ia-hGdO0-9"
      },
      "source": [
        "### The Pytorch Dataloader\n",
        "PyTorch offers a convenient class called DataLoader, which simplifies the process of shuffling and creating mini-batches for you.\n",
        "\n",
        "With DataLoader, you can transform any Python collection into an iterator over mini-batches, as demonstrated below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMjCTZGFPCbr",
        "outputId": "a06bf0a9-f860-4fdf-90e1-b7a00c6890cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_col:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 9,  6,  3,  8, 11]),\n",
              " tensor([10,  2, 14,  5, 12]),\n",
              " tensor([ 0,  7,  1, 13,  4])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "number_col = range(15)\n",
        "print('number_col:{}'.format(list(number_col)))\n",
        "dl = torch.utils.data.DataLoader(number_col, batch_size=5, shuffle=True)\n",
        "list(dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3ht64qT96V"
      },
      "source": [
        "When training a model, we typically need a structured collection containing both independent and dependent variables (i.e., model inputs and corresponding targets). In PyTorch, such a collection is referred to as a Dataset. Here, we can put together the labels and the standardized tensors into the dataset form (x,y):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PimyFEUWGy7",
        "outputId": "e77eca1f-9df9-4f47-c087-46c4cc315241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), 5)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dset = list(zip(standardized_tensors,train_labels))\n",
        "x,y = dset[0]\n",
        "x.shape,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o2pMIXbPpWh"
      },
      "source": [
        "We can achieve use the same dataloader function to shuffle and create mini-batches of our standardized MNIST image tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFMEjNptP3Qz",
        "outputId": "6b149276-6caa-413e-c91b-39e4fd681961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "standardized_tensors shape: torch.Size([60000, 784])\n",
            "train_labels len: 60000\n",
            "\n",
            "train_dataloader_list total length: 938\n",
            "60000 images/ 64 batches: 937.5\n",
            "first batch x shape: torch.Size([64, 784])\n",
            "first batch y shape: torch.Size([64])\n",
            "last batch x shape: torch.Size([32, 784])\n",
            "last batch y shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "print('standardized_tensors shape: {}'.format(standardized_tensors.shape))\n",
        "print('train_labels len: {}'.format(len(train_labels)))\n",
        "print()\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dset, batch_size=64, shuffle=True)\n",
        "\n",
        "train_dataloader_list = list(train_dataloader)\n",
        "print('train_dataloader_list total length: {}'.format(len(train_dataloader_list)))\n",
        "print('60000 images/ 64 batches: {}'.format(60000/64)) # the last batch has 32 images only\n",
        "print('first batch x shape: {}'.format(train_dataloader_list[0][0].shape)) #64 standardized image tensors\n",
        "print('first batch y shape: {}'.format(train_dataloader_list[0][1].shape)) #64 image labels\n",
        "print('last batch x shape: {}'.format(train_dataloader_list[-1][0].shape)) #32 standardized image tensors\n",
        "print('last batch y shape: {}'.format(train_dataloader_list[-1][1].shape)) #32 image labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdIhz2QeS9i6"
      },
      "source": [
        "Notice how the 60000 MNIST training images has been shuffled into 938 batches of 64 images in each batch. (except the last one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9L2JZ-dXv2S"
      },
      "source": [
        "### Review Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcndvsB5ZLOF"
      },
      "source": [
        "We can review if our Pytorch dataloader is working well. First lets enumerate the dataloader and load the first batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr3zHpJdZXV9",
        "outputId": "97e0385a-f94d-4896-f1e0-3ede0c2406ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_data.shape: torch.Size([64, 784])\n",
            "len(example_targets): 64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "example_data, example_targets = first(train_dataloader)\n",
        "\n",
        "print('example_data.shape: {}'.format(example_data.shape))\n",
        "print('len(example_targets): {}'.format(len(example_targets)))\n",
        "example_data[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5a-yQdIZWJ3"
      },
      "source": [
        "First batch (batch index=0) has 64 standardized tensor images and 64 corresponding labels. We can plot some of them using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "qBSIdVt-aV8H",
        "outputId": "834ea076-6f0c-4fa1-b567-85eff6246531"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  #convert back to orig shape\n",
        "  original_shape = (28, 28)\n",
        "  numpy_array = example_data[i]\n",
        "  numpy_array = numpy_array.reshape(original_shape)\n",
        "\n",
        "  plt.imshow(numpy_array, cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd-73wVEa4jz"
      },
      "source": [
        "As we can see, our train dataset loader appears to be working fine. To summarize, we first downloaded the data, converted it to tensors, normalized the data, shuffled and split the data into minibatches, finally exposed the data through dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "r9At0Pv8bMy1",
        "outputId": "d22ca563-b30b-4473-9ce0-44b514f60db7"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"738pt\" height=\"44pt\"\n viewBox=\"0.00 0.00 738.25 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 734.25,-40 734.25,4 -4,4\"/>\n<!-- download data -->\n<g id=\"node1\" class=\"node\">\n<title>download data</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"62.39\" cy=\"-18\" rx=\"62.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"62.39\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">download data</text>\n</g>\n<!-- convert to tensor -->\n<g id=\"node2\" class=\"node\">\n<title>convert to tensor</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"230.98\" cy=\"-18\" rx=\"70.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"230.98\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">convert to tensor</text>\n</g>\n<!-- download data&#45;&gt;convert to tensor -->\n<g id=\"edge1\" class=\"edge\">\n<title>download data&#45;&gt;convert to tensor</title>\n<path fill=\"none\" stroke=\"black\" d=\"M124.95,-18C133.28,-18 141.92,-18 150.5,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.53,-21.5 160.53,-18 150.53,-14.5 150.53,-21.5\"/>\n</g>\n<!-- normalize -->\n<g id=\"node3\" class=\"node\">\n<title>normalize</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"383.32\" cy=\"-18\" rx=\"46.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"383.32\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">normalize</text>\n</g>\n<!-- convert to tensor&#45;&gt;normalize -->\n<g id=\"edge2\" class=\"edge\">\n<title>convert to tensor&#45;&gt;normalize</title>\n<path fill=\"none\" stroke=\"black\" d=\"M301.43,-18C309.87,-18 318.41,-18 326.61,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"326.79,-21.5 336.79,-18 326.79,-14.5 326.79,-21.5\"/>\n</g>\n<!-- split &amp; shuffle -->\n<g id=\"node4\" class=\"node\">\n<title>split &amp; shuffle</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"527.86\" cy=\"-18\" rx=\"62.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"527.86\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">split &amp; shuffle</text>\n</g>\n<!-- normalize&#45;&gt;split &amp; shuffle -->\n<g id=\"edge3\" class=\"edge\">\n<title>normalize&#45;&gt;split &amp; shuffle</title>\n<path fill=\"none\" stroke=\"black\" d=\"M429.81,-18C437.95,-18 446.61,-18 455.28,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"455.42,-21.5 465.42,-18 455.42,-14.5 455.42,-21.5\"/>\n</g>\n<!-- DataLoader -->\n<g id=\"node5\" class=\"node\">\n<title>DataLoader</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"678.25\" cy=\"-18\" rx=\"51.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"678.25\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">DataLoader</text>\n</g>\n<!-- split &amp; shuffle&#45;&gt;DataLoader -->\n<g id=\"edge4\" class=\"edge\">\n<title>split &amp; shuffle&#45;&gt;DataLoader</title>\n<path fill=\"none\" stroke=\"black\" d=\"M590.5,-18C598.88,-18 607.48,-18 615.86,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"615.93,-21.5 625.93,-18 615.93,-14.5 615.93,-21.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7de7958c3130>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#hide\n",
        "gv('''\n",
        "\"download data\"->\"convert to tensor\"->\"normalize\"->\"split & shuffle\"->\"DataLoader\"\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upeS77ztbMOZ"
      },
      "source": [
        "Instead of doing all the steps individually, wouldn't it be easy if we did this all in one go? There is a simplified way for doing just that using Pytorch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n96RBE5uXYKk"
      },
      "source": [
        "### Simplified Code for DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sep4mZ1SvF6R"
      },
      "outputs": [],
      "source": [
        "# Define a custom transform function to flatten the tensor\n",
        "def flatten_transform(data):\n",
        "    # Assuming 'data' is a PyTorch tensor of size [batch_size, 28, 28]\n",
        "    # batch_size, height, width = data.size()\n",
        "    return data.view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xNR0fw-ocauP"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 64\n",
        "batch_size_test = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                               flatten_transform\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                               flatten_transform\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSIuGi6Scju8"
      },
      "source": [
        "How simple is that!\n",
        "- We have downloaded the data using `download=True`,\n",
        "- converted the images to tensor and normalized it using known harded coded values for mean(0.1307) and std(0.3081) for MNIST train dataset.\n",
        "- shuffled using `shuffle=True` parameter\n",
        "- mini-batched using `batch_size` parameter\n",
        "\n",
        "Using the `train=True/False` parameter, we have created a dataloader for the test loader as well. Note that, the test loader is using the same mean and std values as we did for train. This is because, any datapreprocessing we apply for train should be applied \"as-is\" for test as well. Moreover, peeping the test data to calculate mean and std is still cheating under the ML rule book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01JWc4xvbHY"
      },
      "source": [
        "Lets make sure our new dataloader using Pytorch is returning the corret shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOI34QdwvhLp",
        "outputId": "b4c610d0-7938-4323-ecbf-85cb9ec5e88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "example_data.shape: torch.Size([64, 784])\n",
            "len(example_targets): 64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_data, example_targets = first(train_loader)\n",
        "\n",
        "print('example_data.shape: {}'.format(example_data.shape))\n",
        "print('len(example_targets): {}'.format(len(example_targets)))\n",
        "example_data[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSuYFg3swDPu"
      },
      "source": [
        "Lets check this for test loader as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqO_MgzWwF3t",
        "outputId": "d7f063cd-7ece-42a6-826a-8c62ac5379e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "example_data.shape: torch.Size([64, 784])\n",
            "len(example_targets): 64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_data, example_targets = first(test_loader)\n",
        "\n",
        "print('example_data.shape: {}'.format(example_data.shape))\n",
        "print('len(example_targets): {}'.format(len(example_targets)))\n",
        "example_data[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM8cuJ5MwJRP"
      },
      "source": [
        "We are good to proceed further!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jduQR5jbvq4D"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCVWV20Dd4OE"
      },
      "source": [
        "### Neural Network\n",
        "Lets create a neural network model from scratch. We will start with a simple single layer neural network with the number of inputs to be same size as the pixels we have and the output layer to have 10 outputs. Neural network equation is $$y=wx+b$$.\n",
        "\n",
        "**Input & Output:** Before we design our neural network, we have to think about our input and output. Lets take one input and one output. Our input x is an image which has 784 pixels (28x28). i.e., we have 784 numbers for x, output. Our output is a prediction for one of the 10 classes. Therefore, y has to have 10 outputs.\n",
        "\n",
        "![png](neural_network_rep.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ovNT5Gm703D"
      },
      "source": [
        "**Weights & Biases:** Next we have to think about the shape of weights & bias as well. For this, we will work our way in reverse. We know we need 10 outputs. Bias is a number that gets added to wx to generate 10 outputs. Thus we know we need 10 numbers for bias. For calculating the shape of the weights, we made things simple by flattening our input image which now has 784 numbers for pixel values. Thus the weights should match the input size which is 784. Note the product of weights & input (wx) gets added to bias,  so the weights should also match the shape of bias. Thus weights should be a dimensional matrix of shape (input size, num_classes).\n",
        "\n",
        "![png](neural_network_multiplication.png)\n",
        "\n",
        "We can apply the same logic for batch processing and we will get the same results for the entire batch.\n",
        "\n",
        "![png](neural_network_multiplication_batch.png)\n",
        "\n",
        "Now that we have taken care of the math, first, we want to create a function for initializing the parameters.\n",
        "Lets assume a basic single layer neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcchDNdweRvJ"
      },
      "outputs": [],
      "source": [
        "def init_params(size, std=1.0, requires_grad = True):\n",
        "    \"\"\"\n",
        "    Initialize model parameters with random values.\n",
        "\n",
        "    Args:\n",
        "    - size (tuple): The size or shape of the parameter tensor.\n",
        "    - std (float): The standard deviation of the random values (default is 1.0).\n",
        "\n",
        "    Returns:\n",
        "    - params (tensor): A tensor containing randomly initialized values for model parameters.\n",
        "    \"\"\"\n",
        "    # Generate random values from a normal distribution with mean 0 and standard deviation 'std'.\n",
        "    random_values = torch.randn(size) * std\n",
        "\n",
        "    # Mark the tensor to require gradients, indicating that it's a learnable parameter.\n",
        "    if requires_grad:\n",
        "      params = random_values.requires_grad_()\n",
        "    else:\n",
        "      params = random_values\n",
        "\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJx1kDt6kAO_",
        "outputId": "e81ab5a0-dcc3-48f7-ae74-ca49ebae0123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = init_params((28*28,10))\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA0RlJxQByRU"
      },
      "source": [
        "We will set the bias to have 10 outputs. y=wx represents only a linear relationship. Adding bias b increases the flexibility of the model to travel anywhere along the y-axis.\n",
        "\n",
        "**Why need bias?**\n",
        "The bias term represents an offset or an intercept in the model. It allows the model to capture a baseline or an average value that is independent of the input features. Without the bias, the model would always pass through the origin (0,0) and could only represent relationships that go through the origin. Including a bias term increases the flexibility of the model. Without it, the model's hypothesis space is constrained to linear relationships passing through the origin, which might not be suitable for capturing complex patterns in the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBDdNG40m_ZC",
        "outputId": "fde4d8f4-1f89-41e9-8754-9325faf00e37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bias = init_params(10)\n",
        "bias.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W_BHnGGna7g",
        "outputId": "4efaa1f5-59b9-485d-8a4f-71fe3ffb6b76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb,yb = next(iter(train_loader))\n",
        "xb.shape,yb.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3qv3YS2FCfX"
      },
      "source": [
        "Lets try calculating the prediction for one image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQJdevNqFR8N",
        "outputId": "305437c9-23cd-443f-84a8-090372b8dfe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(xb[0]@weights).shape # \"@\" symbol for matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOAx81MIFFyl",
        "outputId": "1760b022-25f5-4581-c756-2fe75be033ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 24.3919, -51.7686,  13.9901, -22.6144,  47.2925,   4.1529, -24.6324, -37.5008,  47.0262,  35.0089], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = (xb[0] @ weights) + bias #y = wx + b\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUnSgF5jJqiE"
      },
      "source": [
        "We seem to get some predictions numbers. If our task was a binary classification task, we can easily assume any positive number as positive classification and vice versa.\n",
        "\n",
        "However, since this is a multi-label classification task, where each sample may belong to multiple classes, the prediction with the highest value is the class our simple linear model has classified the image as."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiNiSLlxOtDX"
      },
      "source": [
        "Lets get the argument (position) of the highest prediction value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1pIdzjePNuD",
        "outputId": "002bfdba-ef82-4ec1-f854-b2749b22756a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted output:4\n",
            "actual output:4\n"
          ]
        }
      ],
      "source": [
        "# Get the index of the maximum value\n",
        "max_index = pred.argmax()\n",
        "print(\"predicted output:{}\".format(max_index))\n",
        "print(\"actual output:{}\".format(yb[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7O6QPRBPVA-"
      },
      "source": [
        "Note: At this point, we are only getting the position of the max prediction value. The model does not know if it is predicting a 7 or a 3 or anything else. All the model is doing is giving its calculations for the 10 output positions.\n",
        "\n",
        "Then you might ask, How can we tell what the model is predicting. This comes up only in the next step when we calculate Loss=(Prediction-Target). Only when the loss value is backpropagated, the model will know it tried to predict a highest value for position 3 however, the target value shows highest result for position 7. Thus by lining up the 10 predicted numbers with the 10 output targets, the model would know it needs to adjust its numbers to render a highest score on position 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYcwr4_YRfem"
      },
      "source": [
        "### Softmax function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp89FWP5RlhG"
      },
      "source": [
        "In the above example, you might ask, we already know the model's prediction. Isn't it enough to compare with the right answer and train whether the model is right or wrong? Can't we simply ignore the rest of the 9 numbers? No, we should not. Because, the model needs to learn from the incorrect answers as well.\n",
        "\n",
        "But, we have a problem. The numbers seem to be over a wide range. The above example has a highest value of 45.2565 and lowest value of -23.6937. This is just for one image. Imagine doing this for multiple images and we will end up with multiple range of numbers. How can we make meaningful interpretation from these numbers? We need a common numbering system for the model's output. (Hint: Normalization)\n",
        "\n",
        "This is where the SoftMax Function comes in handy. The softmax function grabs a vector of arbitrary real numbers and turn it into probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7HB6g45Ux5C"
      },
      "source": [
        "[!png](softmax_function.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWQ_etzdU3A7"
      },
      "source": [
        "In summary,\n",
        "1.  First, the model looks at each picture and measures how confident it is that a specific digit is in the picture. For example, if the machine sees a picture that looks a lot like the number 3, it will give it a high score for being the digit 3. If it's not sure, it might give it a lower score.\n",
        "\n",
        "2. Next, the Softmax Function takes all these scores and turns them into probabilities. It ensures that the sum of all the scores equals 100% (or 1 in decimal form). So, the digit with the highest score gets the highest probability, and the one with the lowest score gets the lowest probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj13RAjSWCoF"
      },
      "source": [
        "### Normalization vs Softmax\n",
        "You might ask isn't Softmax same as Normalization? No, they are different.\n",
        "\n",
        "1. **Normalization**:\n",
        "   - Normalization refers to scaling data to have zero mean and unit variance or scaling it to a specific range (e.g., [0, 1]). It is used for data preprocessing and feature scaling.\n",
        "   - Normalization doesn't change the fundamental characteristics of the data. It helps improve training convergence, especially for algorithms like gradient descent, by ensuring that features are on a similar scale.\n",
        "   - It doesn't determine probabilities or make decisions; it's about feature scaling and numerical stability.\n",
        "\n",
        "2. **Softmax Function**:\n",
        "   - The softmax function is a specific activation function used in the output layer of a neural network for multi-class classification tasks.\n",
        "   - It takes a vector of real numbers and converts them into a probability distribution over multiple classes. It assigns probabilities to each class, ensuring that they sum up to 1.\n",
        "   - The softmax function is crucial for determining class probabilities and making decisions in classification problems. It's used to model the likelihood of each class given the network's input.\n",
        "   - Softmax is used to map the model's raw scores (logits) into class probabilities, allowing you to choose the class with the highest probability as the predicted class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdJ9cIPepG43"
      },
      "source": [
        "### SoftMax Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TvY9RaypejS"
      },
      "source": [
        "The softmax formula transforms the prediction output in a way that makes the biggest number the most likely choice, the next biggest number the second most likely choice, and so on.\n",
        "\n",
        "$$  \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} $$\n",
        "\n",
        "In simple terms, softmax formula takes the \"evidence\" or \"confidence\" in each category $$x_i$$, amplifies it using exponentiation $$\\exp(x_i)$$, and then calculates the probability of the input with respect to rest of the evidences across all categories $$\\frac{1}{\\sum_j \\exp(x_j)}$$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDGDd72HvhmH"
      },
      "source": [
        "For implementation, we have to think numerical stability. In the softmax function, we need to exponentiate the elements of a vector. The problem arises when you need to compute the exponential of a large or small number, it can result in numerical overflow or underflow. This causes the output of Softmax to end up with `nan` outputs.\n",
        "\n",
        "So to implement the softmax formula, we have to use the max subtraction of the [log-sum-exp trick](https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/). Given a set of values $$(x_1, x_2, x_3, \\ldots, x_n)$$, we would find the maximum value, $$(M = \\max(x_1, x_2, x_3, \\ldots, x_n))$$, and then compute the exponentials as follows:\n",
        "\n",
        "   $$\n",
        "   \\text{exp}(x_1, x_2, x_3, \\ldots, x_n) = e^{x_1 - M} + e^{x_2 - M} + e^{x_3 - M} + \\ldots + e^{x_n - M}\n",
        "   $$\n",
        "\n",
        "   The subtraction of \\(M\\) helps prevent overflow,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci2za5HGpO7G"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    \"\"\"\n",
        "      Compute softmax scores given the raw output from the model\n",
        "        :param scores: raw scores from the model (N, num_classes)\n",
        "        :return:\n",
        "            prob: softmax probabilities (N, num_classes)\n",
        "      \"\"\"\n",
        "    #check dim\n",
        "    if (len(x.shape)==2):\n",
        "      # Exponentiate each element of the input along dim=1\n",
        "      exp_x = torch.exp(x - x.max(dim=1, keepdim=True).values)\n",
        "      # Calculate the sum of exponentiated values along dim=1\n",
        "      sum_exp_x = torch.sum(exp_x, dim=1, keepdim=True)\n",
        "    else:\n",
        "      exp_x = torch.exp(x)\n",
        "      sum_exp_x = torch.sum(exp_x)\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the softmax probabilities for each element along dim=1\n",
        "    softmax_probs = exp_x / sum_exp_x\n",
        "\n",
        "    return softmax_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSyQimQRr6mp"
      },
      "source": [
        "Lets try this sofmax function out. We expect the sum of the outputs to add up to 1.0 (100% probability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s9TKhpUsFsE",
        "outputId": "08e4030f-1895-4884-f6ac-5714e43e2190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prob.sum():1.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prob = softmax(pred)\n",
        "print(\"prob.sum():{}\".format(prob.sum()))\n",
        "prob.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH8L4vKMvHS8"
      },
      "source": [
        "Note that unlike normalization where we would have 0 mean and 1 standard deviation, the softmax doesnt affect the mean or standard deviation. However, it affects the sum of probabilities totalling to 1.0.\n",
        "\n",
        "We have now converted the output of the predictions into probabilities across the output classes. Lets quickly check if our result is the same as we saw earlier with plain predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvnHjgRju-89",
        "outputId": "a3839209-0d5b-4148-8843-4f9a539ad1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted output:4\n",
            "actual output:4\n"
          ]
        }
      ],
      "source": [
        "# Get the index of the maximum value\n",
        "max_index = prob.argmax()\n",
        "print(\"predicted output:{}\".format(max_index))\n",
        "print(\"actual output:{}\".format(yb[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kJVWXbOhky"
      },
      "source": [
        "Now that we have the individual components, we can put them together into a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34eSTIQ4OqX0"
      },
      "outputs": [],
      "source": [
        "def simple_net(xb):\n",
        "  pred = xb @ weights + bias\n",
        "  prob = softmax(pred)\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dO3E4h9JUTb"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3IS-TRKu5JS"
      },
      "source": [
        "Now that we have the predicted probabilities for the MNIST digits 0-9, we want to determine the losses so we can feed it back to alter the weights during back propagation.\n",
        "\n",
        "As mentioned earlier, we dont want to pick the maximum probability and discard the remaining outputs as the wrong answers too are helpful for the model to learn. Example: if a model says, it is 50% confident an image is a 6, but the actual output is 9, we want to train the model so the confidence for 6 goes down. Ideally, the model should say 0% probability for 6 (and every other number), except for 9 which should have 100% probability.\n",
        "\n",
        "Since we have decided to retain all the output answers, the next question is how do we extract the loss for each classification output? The **Cross Entropy Loss Function** comes to our rescue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeGsSGu0Cln"
      },
      "source": [
        "### Cross-entropy loss\n",
        "- The categorical cross-entropy loss is exclusively used in multi-class classification tasks, where each sample belongs exactly to one of the N classes.\n",
        "- Cross-entropy loss measures the difference between predicted probabilities and true labels.\n",
        "- It heavily penalizes confident incorrect predictions.\n",
        "- By minimizing this loss, the model learns to make more accurate predictions, which is the essence of classification in machine learning.\n",
        "- The true label can be represented by an one-hot encoded vector of size N, which has the value one for the correct class and zero everywhere else, see example below for N = 4:\n",
        "\n",
        "$$\\text{label}_{4}= 2\\rightarrow y = \\begin{pmatrix}\n",
        "     0\\\\\n",
        "     0\\\\\n",
        "     1\\\\\n",
        "     0\\\\\n",
        " \\end{pmatrix} $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EjBHNDK1ben"
      },
      "source": [
        "### Cross-entropy formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9nqB-RA1eym"
      },
      "source": [
        "The formula for categorical cross-entropy loss (also known as softmax loss or log loss) is calculated as:\n",
        "$$ \\text{Categorical Cross-Entropy Loss} = -\\sum_{i}^{N} y_i \\cdot \\log(p_i)$$\n",
        "\n",
        "Let's break down the formula for Categorical Cross-Entropy Loss step by step to understand it better.\n",
        "\n",
        "1. **\\(\\sum_{i}\\)**: This symbol stands for summation, which means we are summing over all the classes. In a multi-class classification problem, there can be many classes (e.g., classes for digits 0-9 in MNIST), and \\(i\\) represents each class.\n",
        "\n",
        "2. **\\(y_i\\)**: \\(y_i\\) is the true probability (or one-hot encoded label) for class \\(i\\). In one-hot encoding, it's a binary value that is 1 for the true class and 0 for all other classes. For example, if you're classifying digits and the true class is 3, \\(y_i\\) would be 1 for \\(i = 3\\) and 0 for all other \\(i\\).\n",
        "\n",
        "3. **\\(p_i\\)**: \\(p_i\\) is the predicted probability for class \\(i\\) given by your model. This is the probability that the model assigns to the input example belonging to class \\(i\\).\n",
        "\n",
        "4. **\\(-\\log(p_i)\\)**:\n",
        "- When \\(y_i = 1\\), it means that the true label for the example corresponds to class \\(i\\). In other words, the true class is class \\(i\\).\n",
        "- When the model assigns a high probability (\\(p_i\\)) to the true class (class \\(i\\)), the loss for that class becomes low because \\(-\\log(1) = 0\\).\n",
        "- However, when the model assigns a low probability to the true class, the loss for that class becomes high because \\(-\\log(p_i)\\) is a positive value for \\(p_i < 1\\). The more the predicted probability deviates from 1 (i.e., it's lower than expected), the higher the loss.\n",
        "\n",
        "\n",
        "5. **\\(-\\sum_{i} y_i \\cdot \\log(p_i)\\)**: Finally, we sum up these \\(-\\log(p_i)\\) terms over all classes. This summation measures the overall dissimilarity between the predicted probability distribution (\\(p_i\\)) and the true probability distribution (\\(y_i\\)).\n",
        "\n",
        "The Categorical Cross-Entropy Loss quantifies how well the predicted probabilities match the true probabilities (one-hot encoded labels) for a multi-class classification problem. It encourages the model to increase the predicted probability for the true class while reducing the predicted probabilities for other classes. Minimizing this loss during training helps the model make better class predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hBZIe2O5C0j"
      },
      "source": [
        "### Cross-Entropy Loss Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka6CSrvyJZH7"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(y_true, y_pred, num_classes = 10):\n",
        "    \"\"\"\n",
        "    Compute the Categorical Cross-Entropy Loss for a single example.\n",
        "\n",
        "    Args:\n",
        "    - y_true: True label for classes.\n",
        "    - y_pred: Predicted probability distribution for classes.\n",
        "\n",
        "    Returns:\n",
        "    - loss: Categorical Cross-Entropy Loss for the example.\n",
        "    \"\"\"\n",
        "    # Convert y_true label to one hot encoded label\n",
        "    onehot_y = torch.eye(num_classes)[y_true]\n",
        "\n",
        "    # Ensure that onehot_y and y_pred have the same shape\n",
        "    assert onehot_y.shape == y_pred.shape, \"Shapes of y_true and y_pred must match.\"\n",
        "\n",
        "    # Compute the loss using the formula\n",
        "    # Apply the log-sum-exp trick to the computation of the logarithm\n",
        "    # This helps in preventing overflow or underflow when dealing with large or small probabilities\n",
        "    loss = -torch.sum(onehot_y * torch.log(torch.clamp(y_pred, 1e-10, 1.0)))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37R18amDkjLb"
      },
      "source": [
        "NOTE: Some of the probablities in y_pred are extremely tiny. Such tiny values are almost close to 0. Trying to do a log() of 0 is inf. This leads to underflow(nans) and overflows(inf). So we clamp the y_preds and consider only a predefined range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGx9ZFjz5vGy"
      },
      "source": [
        "Lets test out the cross entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQ73mBt6qcL",
        "outputId": "e5c09b0c-a704-42d9-b88d-4b981d7bba24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.5688, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_entropy_loss(yb[0], prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_94g6YwA-_Pg"
      },
      "source": [
        "Lets try out some toy examples. Suppose the predicted probability is (0.8, 0.1,0.1) is close to the true probability is (1,0,0). We expect the loss to be cross entropy loss to be low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwZJlRD-_aJl",
        "outputId": "3a9a1396-dd27-490c-b30c-21542281cabb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.2231)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = 0\n",
        "y_pred = torch.tensor([0.8,0.2,0.2])\n",
        "cross_entropy_loss(y_true, y_pred, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FYPFrpz_56U"
      },
      "source": [
        "On the contrary, if predicted probability(0.2, 0.6,0.2) is far off from the true probability is (1,0,0). We expect the loss to be cross entropy loss to be higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLxR0AzDAV1b",
        "outputId": "e202e8f7-36f5-440c-8f26-6dcfc4ac4596"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.6094)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = 0\n",
        "y_pred = torch.tensor([0.2,0.6,0.2])\n",
        "cross_entropy_loss(y_true, y_pred, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoDziMSNAcld"
      },
      "source": [
        "So we have proved our loss function is working as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRXjVfer7kYD"
      },
      "source": [
        "So far, this is how our model architecture is looking after adding softmax and cross entropy layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i5mNtD57tF8"
      },
      "source": [
        "![png](model_architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_XII8zcBNiC"
      },
      "source": [
        "## Gradient Descent - Manual Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXPQG4wnBQFm"
      },
      "source": [
        "Now that we have the forward pass with activation, lets calculate the backward pass to determine gradients.\n",
        "\n",
        "Similar to my [gradient descent article]({% post_url 2023-09-14-Gradient_Descent_Basics %}), we will follow the below steps to determine gradients and update our parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lxm4FrNv5kM"
      },
      "source": [
        "1. run model & get predictions\n",
        "2. calc loss from predictions & true labels\n",
        "3. calculate gradients\n",
        "4. update gradients\n",
        "\n",
        "In terms of Pseudocode, we get:\n",
        "```python\n",
        "for x,y in dl:\n",
        "    pred = model(x) #run model & get predictions\n",
        "    loss = loss_func(pred, y) #calc loss from predictions & true labels\n",
        "    loss.backward() #calculate gradients\n",
        "    parameters -= parameters.grad * lr #update gradients\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wygt_DQgMnDQ"
      },
      "source": [
        "![png](gradient_descent.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOpFVu5Vwbck"
      },
      "source": [
        "### Run Model & Calc Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BtqeQO_EuBv"
      },
      "source": [
        "We will first reinitialize our parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pXn-2kvE1S0",
        "outputId": "309eaacb-500a-4d9f-e9ac-2b65b675d27c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]), torch.Size([10]))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = init_params((28*28,10), requires_grad = False) #note: we have turned off requires grad\n",
        "bias = init_params(10, requires_grad = False) #note: we have turned off requires grad\n",
        "weights.shape,  bias.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPvLFNsbFBPv"
      },
      "source": [
        "We will create a mini-batch of size 4 for testing:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaHUsBxYFEsq",
        "outputId": "7003927a-4b34-4566-f8e6-a75123c1f951"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 784])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = example_data[:4]\n",
        "batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaun-I9tFPZh"
      },
      "source": [
        "We will run this simple minibatch sample through our model and get predictions. Since predictions are probabilities (across 10 output layers) from the softmax layer, we expect the sum of all predictions to equate to 1.0 (100% probability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbqqazcYFViv",
        "outputId": "09205582-57e2-414f-c78d-ea697b555739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preds.shape:torch.Size([4, 10])\n",
            "simple_net -  preds:tensor([6.5931e-01, 1.0749e-29, 2.3680e-19, 5.9656e-41, 1.0338e-38, 1.2225e-03, 3.3947e-01, 3.7747e-12, 1.2969e-30, 2.8681e-08])\n",
            "simple_net -  sum of preds:1.0\n",
            "simple_net -  preds:tensor([8.2832e-09, 2.0217e-19, 2.5385e-23, 1.1825e-23, 1.8589e-10, 4.6610e-17, 4.9582e-01, 3.5712e-23, 5.0418e-01, 2.5376e-24])\n",
            "simple_net -  sum of preds:1.0\n",
            "simple_net -  preds:tensor([7.6778e-01, 3.7658e-03, 1.7342e-10, 4.6965e-13, 2.7946e-34, 7.2466e-12, 2.2846e-01, 2.2359e-07, 7.2267e-22, 4.2496e-19])\n",
            "simple_net -  sum of preds:1.0000001192092896\n",
            "simple_net -  preds:tensor([1.0000e+00, 1.9510e-28, 2.9353e-10, 1.1456e-20, 5.0176e-28, 8.8912e-07, 6.2503e-19, 1.9154e-26, 2.3416e-30, 4.6136e-22])\n",
            "simple_net -  sum of preds:1.0\n"
          ]
        }
      ],
      "source": [
        "preds = simple_net(batch)\n",
        "print(\"preds.shape:{}\".format(preds.shape))\n",
        "for i in preds:\n",
        "  with torch.no_grad():\n",
        "    print(\"simple_net -  preds:{}\".format(i))\n",
        "    print(\"simple_net -  sum of preds:{}\".format(i.sum())) #sum of preds should be 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj_S-DylGF44"
      },
      "source": [
        "Looking at the results, we have 4 rows of 10 probabilities for with the model's prediction in terms of probability for each of the 10 classes. Note with the help of Pytorch's broadcasting, we dont have to reshape the simple_net model.\n",
        "\n",
        "Next, we will calculate the cross entrophy loss to see how well our model is performing with respect to the true classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htZpg2hjGDIn",
        "outputId": "5ef92248-5460-43db-9011-83887eedee50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(92.1034)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = cross_entropy_loss(example_targets[0:4], preds)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_rfMdD6wmIw"
      },
      "source": [
        "### Calculate Gradients\n",
        "- Calculus helps us to calculate whether our loss will go up or down when we adjust our parameters up or down.\n",
        "- From Calculus basics, derivative of a function tells us how much change in its parameters will change its result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoDH-2Wn1DPG"
      },
      "source": [
        "Before we can calcuate the derivative of a function, we need to represent our model using a **computation graph**. Computation graph is a visual representation of mathematical operations and their dependencies. It helps us describe the flow of data and operations in a mathematical model. Computation graph will help us calculate the gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx8G_KL2H1j"
      },
      "source": [
        "**Computation Graph:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrD1B5_U-sVT"
      },
      "source": [
        "![png](computation_graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J5kBbXfAFPw"
      },
      "source": [
        "As we can see computation graph is similar to the model architecture but tries to detail out every mathematical function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVt-5KQ9Aeyn"
      },
      "source": [
        "**Calculate Derivatives:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qZy0aLBDCb"
      },
      "source": [
        "Now that we have the computation graph, our intent is to calculate the derivative of the Loss with respect to the parameters (weights & biases). i.e., $$\\frac{dL}{dW}$$ & $$\\frac{dL}{db}$$. Calculating these values in one go will be an extremely difficult thing to do. This is why computation graph is helpful: we can walk back from loss and calculate the gradient at each mathematical operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZieWpALDOI-"
      },
      "source": [
        "![png](computation_graph_derivative.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXyIz50DhJl"
      },
      "source": [
        "As shown in the image below, we can start from the end. We have the loss value result.\n",
        "- Using the loss value result, and knowing the derivative of the cross-entropy loss & Softmax function, we calculate $$dL/dz$$ as follows:\n",
        "$$dL/dz = s-y$$\n",
        "- With the result of $$dL/dz$$, we can calculate the derivative of the loss with respect to bias $$dz/db = 1$$ and weights $$dz/db = x$$.\n",
        "- Finally with calculus's chain rule, we can calculate the gradients by putting together the above:\n",
        "$$\\frac{dL}{dW} = \\frac{dL}{dz}.\\frac{dz}{dW} $$.\n",
        "Similarly,\n",
        "$$\\frac{dL}{db} = \\frac{dL}{ds}.\\frac{ds}{dz}.\\frac{dz}{db} $$\n",
        "Once we know the gradients of Loss with respect to the parameters: bias and weights, we can update the parameters with these calculated gradients in order to reduce the loss during the next epoch. You might ask how we arrived at these equations:\n",
        "\n",
        "NOTE: We treat the softmax & cross entropy as one layer and calculate the gradients for this combined unit. This is for numerical stability as the softmax & log operations involved in cross-entropy can produce extremely small or large numbers, which may result in numeric overflow or underflow. This is why we avoid calculating dL/ds and rather directly calculate dL/dz\n",
        "[This article](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1) is an excellent resource that dives into the mathematical details of how the gradients are calculated for softmax and cross entropy layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqX25L7aMVpP"
      },
      "source": [
        "**Code Implementation:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHfBmyHxLkdF"
      },
      "source": [
        "Implementing this is easier said than done. One thing to remember is the size of the gradients would match the size of the actual activations. For instance, if the output of softmax is of shape 64x10, then the derivative at the end of softmax should also be 64x10. (A gradient value for every input). As long as we follow, the same shape when deriving derivatives, we are in safe place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zJ7--nKGib0"
      },
      "source": [
        "We will start with initializing variables for holding the gradients for weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntTbfKTaMT8T"
      },
      "outputs": [],
      "source": [
        "def init_grads(size):\n",
        "    \"\"\"\n",
        "    Initialize model gradients with zero values.\n",
        "\n",
        "    Args:\n",
        "    - size (tuple): The size or shape of the parameter tensor.\n",
        "\n",
        "    Returns:\n",
        "    - params (tensor): A tensor containing randomly initialized values for model parameters.\n",
        "    \"\"\"\n",
        "    # Generate zeros of required size\n",
        "    grads = torch.zeros(size)\n",
        "\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZhhLeqlIL1g",
        "outputId": "453bb242-68c3-4c9e-eddc-7429b125d430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grad_weights.shape:torch.Size([784, 10])\n",
            "grad_bias.shape:torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "grad_weights = init_grads((28*28,10))\n",
        "grad_bias = init_grads(10)\n",
        "print(\"grad_weights.shape:{}\".format(grad_weights.shape))\n",
        "print(\"grad_bias.shape:{}\".format(grad_bias.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2r1WYDCJXF1"
      },
      "outputs": [],
      "source": [
        "def manual_backward(s, y, batch):\n",
        "  \"\"\"\n",
        "    Calculate model gradients. (similar to loss.backward in Pytorch but done manually)\n",
        "\n",
        "    Args:\n",
        "    - s (N,10): probability predictions from softmax layer\n",
        "    - y (N): true labels\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "  with torch.no_grad(): #we do not want to pytorch to calc gradients since we are manually doing it\n",
        "    # =========== 1) calc b2 gradients ===========\n",
        "    #step1: compute dL_ds where L = CE(softmax(Z),y)\n",
        "    #get num of classes\n",
        "    # print(\"s.shape:{}\".format(s.shape))\n",
        "    # print(\"y.shape:{}\".format(y.shape))\n",
        "    num_classes = s.shape[1]\n",
        "    onehot_y = np.eye(num_classes)[y]  # onehot_y = 64 x 10\n",
        "    # print(\"num_classes:{}\".format(num_classes))\n",
        "    # print(\"onehot_y.shape:{}\".format(onehot_y.shape))\n",
        "    # __step1b:subtract s - y (ensure shape of both are (N,10)\n",
        "    # (64,10) (4,10)\n",
        "    dL_dZ = s - onehot_y  # dL_dA = 64 x 10\n",
        "    # print(\"s:{}\".format(s))\n",
        "    # print(\"onehot_y:{}\".format(onehot_y))\n",
        "    # print(\"dL_dZ:{}\".format(dL_dZ))\n",
        "    #step3: calc dL_db [10x1] = dL_dZ[64x10] * ones [64x1]\n",
        "    dZ_db = np.ones((dL_dZ.shape[0],1))\n",
        "    dL_db = np.dot(dL_dZ.T,dZ_db)\n",
        "    #step3: update bias  - divide by batch size N - shape: (10,)\n",
        "    grad_bias = (dL_db/batch.shape[0]).flatten()\n",
        "    # =========== 2) calc W2 gradients ===========\n",
        "    #step1: Compute dZ_dW = X [64x784]\n",
        "    dZ_dW = np.copy(batch)\n",
        "    #step2: find dL_dW = dL_dZ [64x10] * dZ_dW [64x784]\n",
        "    dL_dW = np.dot(dL_dZ.T, dZ_dW).T # [784x10]\n",
        "    # step3: update bias  - divide by batch size N - shape: (10,)\n",
        "    grad_weights= (dL_dW / batch.shape[0])\n",
        "  return torch.from_numpy(grad_weights), torch.from_numpy(grad_bias) #convert to torch before returning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKw8xFe32h_6"
      },
      "source": [
        "Pytorch uses similar technique to calculate gradients. You can read more about it in this [Pytorch Article](https://pytorch.org/blog/computational-graphs-constructed-in-pytorch/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljqCF8mUBWwV",
        "outputId": "3ad8b02a-b3e9-45f5-eeb3-5c55fe4156a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grad_weights.shape:torch.Size([784, 10])\n",
            "grad_bias.shape:torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "grad_weights, grad_bias = manual_backward(preds, example_targets[:4], example_data[:4])\n",
        "#making sure the grad weights and grad bias are of proper shape\n",
        "print(\"grad_weights.shape:{}\".format(grad_weights.shape))\n",
        "print(\"grad_bias.shape:{}\".format(grad_bias.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKhVyUmzM1uz"
      },
      "source": [
        "Great! Now that we have the gradients for weights and bias, lets put it all into a function for easy calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbeKbkRLM8UP"
      },
      "outputs": [],
      "source": [
        "def calc_grad_manual(xb, yb, model):\n",
        "    preds = model(xb)\n",
        "    loss = cross_entropy_loss(yb, preds)\n",
        "    grad_weights, grad_bias = manual_backward(preds, yb, xb)\n",
        "    return grad_weights, grad_bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGevLD4tN6m7"
      },
      "source": [
        "Now lets test out the function using our small mini batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c_JozATOCPI",
        "outputId": "e4cd2e0b-d715-48c1-c37f-0757e35b7cc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-1.4336e-06, dtype=torch.float64),\n",
              " tensor(7.9055e-08, dtype=torch.float64))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grad_weights, grad_bias = calc_grad_manual(batch, example_targets[0:4], simple_net)\n",
        "grad_weights.sum(),grad_bias.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUYSxEDiJNi"
      },
      "source": [
        "### Update parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNJJ7uv7iLk2"
      },
      "source": [
        "- The last step is to update the weights and biases based on the gradient and learning rate.\n",
        "\n",
        "Lets write up a function to take the learning rate, params and model as input, cycle through the input, calculate gradients for the parameters and then finally update the parameters (and also reset it for the next cycle). All this is considered one epoch (aka iteration). For the next iteration, we repeat this process with updating parameters and even learning rate if we consider any decay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmwMQklzjANK"
      },
      "outputs": [],
      "source": [
        "def train_epoch_manual(model, lr, weights,bias):\n",
        "    for xb,yb in train_loader:\n",
        "        with torch.no_grad():\n",
        "          grad_weights, grad_bias = calc_grad_manual(xb, yb, model)\n",
        "          weights -= grad_weights*lr  #update weights\n",
        "          bias -= grad_bias*lr #update weights\n",
        "          #no need to resets gradients to zero as they are calc from scratch\n",
        "    return weights,bias #return updated weights and bias so they can be fed as input during next itration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBLWEoD9qI7-"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdeMFy-1qKsg"
      },
      "source": [
        "During the validation phase, we do not train (update parameters) our model any more. We will evaluate the model to see how well it is doing. Remember, we have validation data as well from MNIST. We will evaluate our model with the validation data. The model will use its trained parameters which are frozen during this validation phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8CHhdakDQj"
      },
      "source": [
        "### Compute Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j6h4PxEkGEP"
      },
      "source": [
        "Although we have loss, it is only used to calculate the gradients. We need a metric for us, humans to decide how good our model is doing with respect to the original task - classifying MNIST images as numbers. We can use a simple accuracy metric - determine how many correct predictions among all the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vV_HycaqmpOf"
      },
      "outputs": [],
      "source": [
        " def compute_accuracy(x_pred, y):\n",
        "  \"\"\"\n",
        "  Compute the accuracy of current batch\n",
        "  :param x_pred: Probabilities from the model (N, num_classes)\n",
        "  :param y: Labels of instances in the batch\n",
        "  :return: The accuracy of the batch\n",
        "  \"\"\"\n",
        "  acc = None\n",
        "  predictions = torch.argmax(x_pred, axis=1)\n",
        "  acc = torch.sum(torch.eq(y, predictions)) / len(predictions)\n",
        "  return acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNzk5eGim_2G"
      },
      "source": [
        "We can quickly check our metric function with our earlier 4 sample images minibatch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq2PWig_nOGG",
        "outputId": "cf263cd0-0131-4043-b789-8cabb3997ef0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_accuracy(preds, example_targets[0:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYQ2Gsdp_7_"
      },
      "source": [
        "### Validation Function\n",
        "\n",
        "For the validation function, we want to run the validation data through our trained model, get those predictions and compute the accuracy metric to decide how well our model is doing. We can write a function for that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5TmKnbTsuemn"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model):\n",
        "    accs = [compute_accuracy(model(xb), yb) for xb,yb in test_loader] #notice how we have used \"test_loader\" to load validation data instead of train loader\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcIlVxgUu0hx",
        "outputId": "5fc129b7-de61-43cd-cb66-067ed81d6dba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0785"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validate_epoch(simple_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO49MAOqvAKX"
      },
      "source": [
        "This accuracy is our starting point with random values for weights and biases. (we havent trained our model yet). In the next section, we will train our model and repeat validation to see how well our model is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFg8ny9au8tc"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpMKkvy0wMIU"
      },
      "source": [
        "The parameters `weights` & `bias` are already setup with `requires_grad_()` so, Pytorch will automatically continue calculating gradients for us. Let's train for one epoch, and see if the accuracy improves. One Epoch here means one iteration through the entire MNIST dataset. So this means cycle through all mini batches of train dataset during the train phase and cycle through all mini batches of test dataset during the test phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMcAYN-Ou-LX",
        "outputId": "5d177da4-5ee7-4911-b7b0-2d4b66a62d12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8776"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = 1.\n",
        "train_epoch_manual(simple_net, lr, weights,bias)\n",
        "validate_epoch(simple_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqSNeMWEw-lp"
      },
      "source": [
        "Our accuracy has improved just after one epoch! Now, lets try training for 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCucdn7exjyM",
        "outputId": "1dd982d6-ec3b-4505-dd47-a5c7d00dca04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.865 0.7881 0.8779 0.8127 0.852 0.8088 0.8378 0.8521 0.8225 0.865 0.8977 0.8944 0.8738 0.8402 0.886 0.8197 0.8669 0.9133 0.8083 0.7729 "
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "    weights,bias = train_epoch_manual(simple_net, lr, weights,bias)\n",
        "    print(validate_epoch(simple_net), end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InLvF4uAxwcU"
      },
      "source": [
        "Excellent! Our training seems to train our model, increasing its accuracy during each epoch. In the next section, lets do the same thing but using Pytorch's auto grad function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRgTAVeZTmHG"
      },
      "source": [
        "## Gradient Descent - Using Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EEPgGHpiewx"
      },
      "source": [
        "Before we attempt gradient descent using Pytorch, we will initialize the weights and bias, setup a small batch, run it through our linear model and calculate loss. Unlike last time using manual approach, this time we want Pytorch to calculate the gradients for us. The default value is True so when we call init_params(), our function defaults to require grads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBCGGEoVimnL"
      },
      "outputs": [],
      "source": [
        "#initialize weights and bias\n",
        "weights = init_params((28*28,10))\n",
        "bias = init_params(10)\n",
        "#setup batch\n",
        "batch = example_data[:4]\n",
        "#predictions\n",
        "preds = simple_net(batch)\n",
        "#calc loss\n",
        "loss = cross_entropy_loss(example_targets[0:4], preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyI0oE3tTvmY"
      },
      "source": [
        "PyTorch is known for its **automatic differentiation capability**, which allows it to compute derivatives of functions with respect to their inputs. This automatic differentiation feature is incredibly powerful for deep learning because it allows you to define complex neural network architectures and loss functions while PyTorch handles the tedious task of calculating gradients.\n",
        "\n",
        "Now we can calculate the gradients using Pytorch which hugely simplifies things. i.e., we do not need the `manual_backward()` from the previous section since Pytorch does it for us. Here is a quick check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rCBcp76TvmY",
        "outputId": "d84bac67-2af6-4a7e-b1b4-0999a6e67927"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]), tensor(2.4328e-10))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.backward()\n",
        "weights.grad.shape,weights.grad.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFzy1fK8jW23"
      },
      "source": [
        "It still surprises me how this one line of code calculates the entire gradients for weights and biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4xGlZITvmY"
      },
      "source": [
        "Lets put the entire logic into a function. We get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "auCSxm4eTvmY"
      },
      "outputs": [],
      "source": [
        "def calc_grad(xb, yb, model):\n",
        "    preds = model(xb)\n",
        "    loss = cross_entropy_loss(yb, preds)\n",
        "    loss.backward() #calc gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_4ntkiUTvmZ"
      },
      "source": [
        "We can also make sure this function is working fine with our micro minibatch with 4 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlxWgT1MTvmZ",
        "outputId": "a6f36549-98f5-45f6-deba-346e09b95123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(3.8147e-06), tensor(0.))"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calc_grad(batch, example_targets[0:4], simple_net)\n",
        "weights.grad.sum(),bias.grad.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocDviRezTvmZ"
      },
      "source": [
        "NOTE: `loss.backward` actually adds the gradients of loss to any gradients that are currently stored. So, we have to set the current gradients to 0 first.\n",
        "\n",
        "If we do not reset the gradients and try to calculate gradients, those calculated gradients will be added to current gradients. So when updating parameters, it would lead to incorrect updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PNoU-a9TvmZ"
      },
      "outputs": [],
      "source": [
        "weights.grad.zero_()\n",
        "bias.grad.zero_();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeaIaQjiT8F1"
      },
      "source": [
        "### Update parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld2TbHDoT8F_"
      },
      "source": [
        "- The last step is to update the weights and biases based on the gradient and learning rate.\n",
        "- When updating the parameters, we have to tell Pytorch to not consider this piece of updating parameters when calculating gradients on the next iteration.\n",
        "- If we assign to the data attribute of a tensor then PyTorch will not take the gradient of that step.\n",
        "\n",
        "Lets write up a function to take the learning rate, params and model as input, cycle through the input, calculate gradients for the parameters and then finally update the parameters (and also reset it for the next cycle). All this is considered one epoch (aka iteration). For the next iteration, we repeat this process with updating parameters and even learning rate if we consider any decay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPCnxjiWT8GA"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, lr, params):\n",
        "    for xb,yb in train_loader:\n",
        "        calc_grad(xb, yb, model)\n",
        "        for p in params:\n",
        "            p.data -= p.grad*lr #p.data tells Pytorch to exclude this step during gradient calculation\n",
        "            p.grad.zero_() #resets gradients to zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esvGhDlXjoNx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ISXjkWjFLfe"
      },
      "source": [
        "We can now run the training for 20 epochs and see how it does on the validation data at the end of each epoch. Note how we do not need to pass in or pass out parameters like we did in the manual way as Pytorch does it for us.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXz2q3Ecjpgi",
        "outputId": "e4cfedc4-c733-4c6b-aad3-a7db6866a46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3074 0.3084 0.3077 0.3092 0.3059 0.3057 0.3091 0.3093 0.3091 0.3076 0.3047 0.3066 0.3077 0.3096 0.3089 0.3088 0.3094 0.3095 0.3091 0.3113 "
          ]
        }
      ],
      "source": [
        "lr = 1.\n",
        "params = weights, bias\n",
        "for i in range(20):\n",
        "    train_epoch(simple_net, lr, params)\n",
        "    print(validate_epoch(simple_net), end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TblX9LSojYe"
      },
      "source": [
        "## Optimizing using Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbDb0YBFqbZI"
      },
      "source": [
        "In this section we will create an Optimizer to optimize the code using Pytorch! (see how I played with words there! :))\n",
        "Well, 'Optimizer' is a Pytorch object that will handle the SGD step for us. We will create a super simple basic optimizer which wil help us to understand how things work in Pytorch. In order to create the Pytorch Optimizer, we first need to rewrite our model using Pytorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg0GIJ80uAGb"
      },
      "source": [
        "### Model in Pytorch\n",
        "\n",
        "Earlier we had used `simple_net()` function to create our model. This model too can be defined in Pytorch which will hugely simplify things for us and help us build more complex models just by describing them and not having to worry about the implementation (as Pytorch will take care of it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yedVt_Xrq8fx"
      },
      "outputs": [],
      "source": [
        "# Define your linear model\n",
        "linear_model = nn.Linear(28 * 28, 10)\n",
        "\n",
        "# Create a model that includes the linear layer and softmax layer\n",
        "simple_net_pytorch = nn.Sequential(\n",
        "    linear_model,\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25-vEKRtHfT"
      },
      "source": [
        "We first define the linear model using nn.Linear. Then, we create a new model called `simple_net_pytorch` using nn.Sequential, which combines the linear layer with a softmax layer. When you pass input data to `simple_net_pytorch`, it will apply the linear transformation and then the softmax activation to produce output probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zufePyysv7T",
        "outputId": "f3429b0d-af90-4eb8-b43c-4c118a2d20ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10, 784]), torch.Size([10]))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w,b = simple_net_pytorch.parameters()\n",
        "w.shape,b.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI2YVdyvtcu3"
      },
      "source": [
        "Excellent! The shape of our parameters shows that this is exactly the same shape of the parameters used with our manual parameter initialization. Also, notice how we only defined our model while Pytorch took care of the parameters shape and initialization for us. Now that we have the model in Pytorch, the next step is to create a Basic Optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf-ymrEZuOHF"
      },
      "source": [
        "### Optimizer in Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS1xnd53uQvF"
      },
      "source": [
        "Below we define a basic optimizer class called BasicOptim. This class is a simple implementation of an optimizer for updating model parameters during training. It has two main methods, step and zero_grad, which are commonly found in optimizers. The BasicOptim takes two arguments: `params` and `lr`. `params` is a list of model parameters that need to be optimized, and `lr` is the learning rate for the optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCjr4S4Lu4zy"
      },
      "outputs": [],
      "source": [
        "class BasicOptim:\n",
        "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
        "\n",
        "    def step(self, *args, **kwargs):\n",
        "        for p in self.params: p.data -= p.grad.data * self.lr\n",
        "\n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        for p in self.params: p.grad = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB-etuJMvGNG"
      },
      "source": [
        "We can already see the how this Basic Optimizer can be used to replace the parameter update step and reset grad steps in the `train_epoch()` we defined earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOCDQtInug9T"
      },
      "source": [
        "Note that PyTorch provide built-in optimizers (e.g., torch.optim.SGD, torch.optim.Adam) that are highly optimized and often come with additional features, like support for various optimization algorithms, learning rate schedules, and weight decay.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiflMIxEv6je"
      },
      "source": [
        " We can now initialize the Basic optimizer so that it will update the parameters of your simple_net_pytorch model with the specified learning rate during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6JqOeA7vuNK"
      },
      "outputs": [],
      "source": [
        "opt = BasicOptim(simple_net_pytorch.parameters(), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTe7rGNxwri6"
      },
      "source": [
        "### Training with Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnFxu22-wPLT"
      },
      "source": [
        "Now that we have our optimizer, our `train_epoch()` can be updated as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQX1VEGRwVDC"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model):\n",
        "    for xb,yb in train_loader:\n",
        "        calc_grad(xb, yb, model)\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7gHpGXlwxkF"
      },
      "source": [
        "Note there is no change to our validation function. We can simply pass in the new model name `simple_net_pytorch`. Lets check out how our untrained parameters performa with the validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SDUqoiuwvqv",
        "outputId": "b5c9bf7a-cf4a-49a0-bbc2-7ce8961eddc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0883"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validate_epoch(simple_net_pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475PdgS1xLsV"
      },
      "source": [
        "We can put all this code together in a function called `train_model()` that trains a model for a specified number of epochs and prints validation results after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbiS3ZjzxRiy"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model)\n",
        "        print(validate_epoch(model), end=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3eyL_FlxYPf",
        "outputId": "d0bcd3b5-4b11-4520-d4ca-0de47515f94f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6968 0.7202 0.7344 0.7285 0.7373 0.7441 0.7267 0.7443 0.7383 0.7501 0.7471 0.7525 0.7522 0.7486 0.7462 0.739 0.7401 0.7495 0.7489 0.747 "
          ]
        }
      ],
      "source": [
        "train_model(simple_net_pytorch, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWlPN4vgx1_6"
      },
      "source": [
        "Excellent, our model seems to training well with our Pytorch simple net model, and Basic Optimizer code. Next, we will replace our Basic Optimizer with Pytorch's built in SGD optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6AAo_4Vy5a3"
      },
      "source": [
        "### Using Pytorch's SGD Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUPfoXcCo-I5"
      },
      "source": [
        "The initialization of the SGD Optimizer is same as Basic Optimizer.  This optimizer takes care of updating the model's parameters and applying the SGD optimization algorithm.\n",
        "\n",
        "This approach is recommended because PyTorch's built-in optimizers are well-tested and optimized, and they provide various options for fine-tuning your optimization process, such as momentum, weight decay, and learning rate schedules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuz-Z7sror13"
      },
      "outputs": [],
      "source": [
        "# Create the SGD optimizer\n",
        "optSGD = torch.optim.SGD(simple_net_pytorch.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZSQx9GupLUA"
      },
      "source": [
        "We will create a new train_epoch() with the SGD Optim. We are only changing the variable name. The method names as same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaBzc6s9pWRx"
      },
      "outputs": [],
      "source": [
        "def train_epochSGD(model):\n",
        "    for xb,yb in train_loader:\n",
        "        calc_grad(xb, yb, model)\n",
        "        optSGD.step()\n",
        "        optSGD.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmdnzYLrpgck"
      },
      "source": [
        "We will also update the train model function to refer to the SGD train_epoch()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHdf3DUmpd0z"
      },
      "outputs": [],
      "source": [
        "def train_modelSGD(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epochSGD(model)\n",
        "        print(validate_epoch(model), end=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cdAQI6OpmDZ",
        "outputId": "9c55c732-b6c1-429f-e685-82bd1b517278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5626 0.5652 0.5647 0.5704 0.571 0.572 0.5754 0.5736 0.5697 0.5753 0.5764 0.5705 0.5782 0.5765 0.5769 0.5728 0.5767 0.5803 0.5761 0.5772 "
          ]
        }
      ],
      "source": [
        "train_modelSGD(simple_net_pytorch, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlnKZza5ovEO"
      },
      "source": [
        "## Increasing Model Complexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH7RUtX_qMMA"
      },
      "source": [
        "So far we have used a super simple model with one linear input layer and Softmax layer for class probabilities. This model is limited in what it can learn. You can see from the previous step that the accuracy of this training gets topped off at 60 to 70\\%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI3jEicyrj8m"
      },
      "source": [
        "### Why Linear Models are Constrained?\n",
        "- Linear classifiers are simple models that can only separate data using linear decision boundaries.\n",
        "- They are suitable for relatively simple classification tasks where the underlying patterns in the data can be captured by straight lines or hyperplanes.\n",
        "- However, many real-world problems require more complex models to capture non-linear relationships in the data. Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn36USs_r_k0"
      },
      "source": [
        "### How do we increase Model Complexity?\n",
        "We can create a more complex model such as a deep neural networks with non-linear activation functions like ReLU, sigmoid, or tanh between linear networks. These Deep learning models can capture intricate patterns in the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVLGXeRhuJOT"
      },
      "source": [
        "### Non-Linear Activation Function: ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUuz1sBnuRZd"
      },
      "source": [
        "- \"ReLU\" stands for \"Rectified Linear Unit.\"\n",
        "- The ReLU activation function is defined as:\n",
        "\n",
        "$$ f(x) = max(0, x) $$\n",
        "\n",
        "- In this formula, \\(x\\) represents the input to the activation function.\n",
        "- If \\(x\\) is greater than or equal to zero, the ReLU function returns \\(x\\).\n",
        "- If \\(x\\) is negative, it returns zero.\n",
        "- This makes it a simple, piecewise linear function with a non-linearity introduced at \\(x = 0\\).\n",
        "- The term \"ReLU\" is used to refer to this specific activation function because it rectifies (i.e., sets to zero) any negative values in the input.\n",
        "- It is one of the most widely used activation functions in deep learning due to its simplicity and effectiveness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "VsS-bap-uzya",
        "outputId": "89cb513b-0c31-4ffe-b725-db6bd3b52241"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Define the range of x values\n",
        "x = np.linspace(-2, 2, 400)\n",
        "\n",
        "# Calculate the corresponding ReLU values\n",
        "relu_values = [F.relu(torch.tensor(val)).numpy() for val in x]\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(x, relu_values, label='ReLU')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.title('ReLU Activation Function')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOp4yquYvnai"
      },
      "source": [
        "### Two Layer Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hr8fLRWvqC5"
      },
      "source": [
        "Lets define a neural network model called `two_layer_net` consists of two linear layers separated by a ReLU activation function and a Softmax activation function. It takes an input vector of size 28*28, applies a linear transformation followed by a ReLU activation, then applies another linear transformation, and finally, applies a Softmax activation to produce class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XLmYtjHEwJgC"
      },
      "outputs": [],
      "source": [
        "# Create a model that includes two linear layers with a ReLU inbetween and softmax layer output\n",
        "two_layer_net_pytorch = nn.Sequential(\n",
        "    nn.Linear(28 * 28, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_beiARQxVNq"
      },
      "source": [
        "### Number of Model Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz7u1j0pxXM-"
      },
      "source": [
        "The number of parameters between our simple_net and two_layer_net have gone up too. This also introduces complexity as the model now has to learn weights and biases for a more unknowns.\n",
        "\n",
        "In our Simple Net model, we have two components:\n",
        "\n",
        "1. `nn.Linear(28 * 28, 10)` - This is a linear layer that maps an input of size 28 * 28 to an output of size 10. It has a weight matrix of shape (10, 784) and a bias vector of shape (10). So, the number of parameters in this linear layer is:\n",
        "\n",
        "   - Number of parameters in the weight matrix = 10 (output features) x 784 (input features) = 7,840.\n",
        "   - Number of parameters in the bias vector = 10.\n",
        "\n",
        "   Total parameters in this linear layer = 7,840 (weight matrix) + 10 (bias vector) = 7,850 parameters.\n",
        "\n",
        "2. `nn.Softmax(dim=1)` - The softmax layer doesn't introduce any new parameters. It's simply a mathematical operation applied to the output of the linear layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w,b = simple_net_pytorch.parameters()\n",
        "w.shape,b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTtr0IP9wUHi",
        "outputId": "51802942-b044-4ec4-df16-4184eebffccc"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 784]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the total number of parameters in our `simple_net_pytorch` model is the number of parameters in the linear layer, which is 7,850 parameters."
      ],
      "metadata": {
        "id": "JqcUmadvwWTU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRtgpibFyRKo"
      },
      "source": [
        "The number of model parameters in our `two_layer_net_pytorch` model, Here's the breakdown:\n",
        "\n",
        "1. **First Linear Layer:**\n",
        "   - Input Features: 28 * 28 = 784\n",
        "   - Output Features: 30\n",
        "   - Number of Parameters (Weights and Biases): (784 input features * 30 output features) + 30 bias terms = 23,550 parameters\n",
        "\n",
        "2. **Second Linear Layer:**\n",
        "   - Input Features: 30\n",
        "   - Output Features: 10\n",
        "   - Number of Parameters (Weights and Biases): (30 input features * 10 output features) + 10 bias terms = 310 parameters\n",
        "\n",
        "3. **Softmax Layer:**\n",
        "   - The Softmax layer does not introduce any additional parameters. It's a normalization operation.\n",
        "\n",
        "Now, we can sum up the parameters from each of the layers to get the total number of model parameters:\n",
        "\n",
        "Total Parameters = 23,550 (First Linear Layer) + 310 (Second Linear Layer) = 23,860 parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1,b1,w2,b2 = two_layer_net_pytorch.parameters()\n",
        "w1.shape,b1.shape,w2.shape,b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIyKPvd-wMTX",
        "outputId": "125bc612-704c-4d49-acdd-2fea84cd7a71"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([30, 784]),\n",
              " torch.Size([30]),\n",
              " torch.Size([10, 30]),\n",
              " torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, our `two_layer_net_pytorch` model has a total of 23,860 parameters. These parameters are used to define the weights and biases that the model learns during training to make predictions. Increasing the number of parameters in a model typically increases its capacity to fit the training data."
      ],
      "metadata": {
        "id": "nsXh6AV3wRZ1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMyRRw43oz9v"
      },
      "source": [
        "## End-to-End Pytorch Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq5-90TxyzZY"
      },
      "source": [
        "### Setup DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Nzl4H9ORzGyH"
      },
      "outputs": [],
      "source": [
        "# Define a custom transform function to flatten the tensor\n",
        "def flatten_transform(data):\n",
        "    # Assuming 'data' is a PyTorch tensor of size [batch_size, 28, 28]\n",
        "    # batch_size, height, width = data.size()\n",
        "    return data.view(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tXxJXyF5zEGK"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 64\n",
        "batch_size_test = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                               flatten_transform\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                               flatten_transform\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIpPHvLaza95"
      },
      "source": [
        "### Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x7P0jpojzdlm"
      },
      "outputs": [],
      "source": [
        "# Create a model that includes two linear layers with a ReLU inbetween and softmax layer output\n",
        "two_layer_net_pytorch = nn.Sequential(\n",
        "    nn.Linear(28 * 28, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODu9ld3gzpSU"
      },
      "source": [
        "### Setup Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rlB2AJCczryU"
      },
      "outputs": [],
      "source": [
        "# Create the SGD optimizer\n",
        "lr= 0.001\n",
        "optSGD = torch.optim.SGD(two_layer_net_pytorch.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Loss Function"
      ],
      "metadata": {
        "id": "PVpfQ6jM04by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_true, y_pred, num_classes = 10):\n",
        "    \"\"\"\n",
        "    Compute the Categorical Cross-Entropy Loss for a single example.\n",
        "\n",
        "    Args:\n",
        "    - y_true: True label for classes.\n",
        "    - y_pred: Predicted probability distribution for classes.\n",
        "\n",
        "    Returns:\n",
        "    - loss: Categorical Cross-Entropy Loss for the example.\n",
        "    \"\"\"\n",
        "    # Convert y_true label to one hot encoded label\n",
        "    onehot_y = torch.eye(num_classes)[y_true]\n",
        "\n",
        "    # Ensure that onehot_y and y_pred have the same shape\n",
        "    assert onehot_y.shape == y_pred.shape, \"Shapes of y_true and y_pred must match.\"\n",
        "\n",
        "    # Compute the loss using the formula\n",
        "    # Apply the log-sum-exp trick to the computation of the logarithm\n",
        "    # This helps in preventing overflow or underflow when dealing with large or small probabilities\n",
        "    loss = -torch.sum(onehot_y * torch.log(torch.clamp(y_pred, 1e-10, 1.0)))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "adpsapUe0_Ad"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Validation Functions"
      ],
      "metadata": {
        "id": "EcES8Huhuhdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def compute_accuracy(x_pred, y):\n",
        "  \"\"\"\n",
        "  Compute the accuracy of current batch\n",
        "  :param x_pred: Probabilities from the model (N, num_classes)\n",
        "  :param y: Labels of instances in the batch\n",
        "  :return: The accuracy of the batch\n",
        "  \"\"\"\n",
        "  acc = None\n",
        "  predictions = torch.argmax(x_pred, axis=1)\n",
        "  acc = torch.sum(torch.eq(y, predictions)) / len(predictions)\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "VASCQH1pseXy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model):\n",
        "  accs = [compute_accuracy(model(xb), yb) for xb,yb in test_loader] #notice how we have used \"test_loader\" to load validation data instead of train loader\n",
        "  return round(torch.stack(accs).mean().item(), 4)"
      ],
      "metadata": {
        "id": "l7ZttvPznbdc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhCwPhTT0u7o"
      },
      "source": [
        "### Setup Training Loops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss_array = [] # for plotting"
      ],
      "metadata": {
        "id": "NPuhCzam-Q9I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-Sq5Ksw305Hq"
      },
      "outputs": [],
      "source": [
        "def train_modelSGD(model, epochs):\n",
        "    for epoch in range(epochs):\n",
        "      #reset running loss term at the start of each epoch\n",
        "      running_loss = 0.0\n",
        "      # Inside each training epoch\n",
        "      for xb,yb in train_loader:\n",
        "        # Forward pass: compute the predictions\n",
        "        preds = model(xb)\n",
        "        # Compute the loss\n",
        "        loss = cross_entropy_loss(yb, preds)\n",
        "        # Backpropagation: compute gradients\n",
        "        loss.backward()\n",
        "        # Update model parameters using the optimizer\n",
        "        optSGD.step()\n",
        "        # Zero out gradients for the next iteration\n",
        "        optSGD.zero_grad()\n",
        "        #update running loss\n",
        "        running_loss += loss.item()\n",
        "        # Validate model with test data\n",
        "      print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "      running_loss_array.append(running_loss / len(train_loader))\n",
        "    print(\"Training finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:  \n",
        "Instead of our custom cross entropy function, you could also use Pytorch's builtin CrossEntropy() by replacing with this line `loss = nn.CrossEntropyLoss()(preds, yb)`. The loss numbers might be a bit different due to our clipping implementation. Otherwise it should work the same."
      ],
      "metadata": {
        "id": "4sJbQVtHA8_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate Untrained Model"
      ],
      "metadata": {
        "id": "mfj-WMquBvij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate_epoch(two_layer_net_pytorch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFCH64LEBz7E",
        "outputId": "19715cb5-3936-4d7b-8a7e-0b679d34108c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1002"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgXCG3ao08ly"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnU0GSZB0-EI",
        "outputId": "b82212e6-9788-4644-c199-80320f9719ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 21.64170510809559\n",
            "Epoch 2, Loss: 12.012829680940998\n",
            "Epoch 3, Loss: 9.28272529616793\n",
            "Epoch 4, Loss: 7.771995860503426\n",
            "Epoch 5, Loss: 6.813918805198629\n",
            "Epoch 6, Loss: 6.1480219960848155\n",
            "Epoch 7, Loss: 5.5584299946898845\n",
            "Epoch 8, Loss: 5.223822747244001\n",
            "Epoch 9, Loss: 4.834864173711998\n",
            "Epoch 10, Loss: 4.5417323889318055\n",
            "Epoch 11, Loss: 4.348731679829961\n",
            "Epoch 12, Loss: 4.027827564062975\n",
            "Epoch 13, Loss: 3.8369525568222187\n",
            "Epoch 14, Loss: 3.672533843833119\n",
            "Epoch 15, Loss: 3.4955074800245924\n",
            "Epoch 16, Loss: 3.364580295392191\n",
            "Epoch 17, Loss: 3.1875008494297323\n",
            "Epoch 18, Loss: 3.051080211345702\n",
            "Epoch 19, Loss: 2.900613680180075\n",
            "Epoch 20, Loss: 2.789949094840903\n",
            "Epoch 21, Loss: 2.678583399398622\n",
            "Epoch 22, Loss: 2.524789593232148\n",
            "Epoch 23, Loss: 2.4927152235751975\n",
            "Epoch 24, Loss: 2.3354366941095543\n",
            "Epoch 25, Loss: 2.2465149307413013\n",
            "Epoch 26, Loss: 2.196204055855269\n",
            "Epoch 27, Loss: 2.1166796047232554\n",
            "Epoch 28, Loss: 1.9974658906753702\n",
            "Epoch 29, Loss: 1.8981787455377421\n",
            "Epoch 30, Loss: 1.8687470412251157\n",
            "Epoch 31, Loss: 1.7183933960698814\n",
            "Epoch 32, Loss: 1.7198061869739851\n",
            "Epoch 33, Loss: 1.6514168239550104\n",
            "Epoch 34, Loss: 1.5461196306723552\n",
            "Epoch 35, Loss: 1.496226408560552\n",
            "Epoch 36, Loss: 1.461776315163114\n",
            "Epoch 37, Loss: 1.370120554558758\n",
            "Epoch 38, Loss: 1.3613034767716297\n",
            "Epoch 39, Loss: 1.267372168176599\n",
            "Epoch 40, Loss: 1.2393794075480655\n",
            "Training finished\n"
          ]
        }
      ],
      "source": [
        "train_modelSGD(two_layer_net_pytorch, 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Train Loss Curve"
      ],
      "metadata": {
        "id": "dqjlSzagBlXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(loss_array, title=\"Loss Curve\", xlabel=\"Epoch\", ylabel=\"Loss\"):\n",
        "    \"\"\"\n",
        "    Plot a loss curve from an array of loss values.\n",
        "\n",
        "    Args:\n",
        "    - loss_array (list): List of loss values to be plotted.\n",
        "    - title (str): Title of the plot.\n",
        "    - xlabel (str): Label for the x-axis.\n",
        "    - ylabel (str): Label for the y-axis.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(loss_array, label=\"Loss\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7sNB4GZ6Bdt3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(running_loss_array, title=\"Training Loss\", xlabel=\"Epoch\", ylabel=\"Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "B-PJPFh_BikG",
        "outputId": "f0068e83-c125-43ce-a94c-6632f32e245c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHV3Ycsf1CcQ"
      },
      "source": [
        "### Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VI3DSubj1O1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fde83a-ca24-4777-dac6-05ae18b4b845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9674"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "validate_epoch(two_layer_net_pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent! We have achieved a good accuracy on our trained model indicating our implementation is working well! We will run some more tests to see if the model is really working."
      ],
      "metadata": {
        "id": "xSFuZJq5B2yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = two_layer_net_pytorch(example_data[5:10])\n",
        "  # find the maximum value and its corresponding index along the second dimension - ignore the max value '_'\n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "  predictions.extend(predicted)\n",
        "  true_labels.extend(example_targets[5:10])\n",
        "\n",
        "# Interpret the predictions\n",
        "for i in range(len(predictions)):\n",
        "    print(f\"Prediction: {predictions[i]}, True Label: {true_labels[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs7leA3BSgTW",
        "outputId": "a98c9e38-971e-4791-a08c-958fb824b3a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 4, True Label: 4\n",
            "Prediction: 6, True Label: 6\n",
            "Prediction: 4, True Label: 4\n",
            "Prediction: 0, True Label: 0\n",
            "Prediction: 7, True Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thats the end of this article. You can access this notebook here. You can check out my other articles as I try to understand ML."
      ],
      "metadata": {
        "id": "McywdFACSrFJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7BQRY9qtW4"
      },
      "source": [
        "## Reference:\n",
        "- https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb\n",
        "- https://nextjournal.com/gkoehler/pytorch-mnist\n",
        "- https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3\n",
        "- https://jaykmody.com/blog/stable-softmax/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}